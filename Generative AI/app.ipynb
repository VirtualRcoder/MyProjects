{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6c0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading documents from the websites\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = ['https://www.screener.in/company/IDFCFIRSTB/consolidated/',\n",
    "        'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/idfcfirstbank/IDF01',\n",
    "        'https://www.cnbctv18.com/market/stocks/idfc-first-bank-share-price/IDF01/']\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d973b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks:  88\n"
     ]
    }
   ],
   "source": [
    "#Converting to Chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000)\n",
    "\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(\"Total Chunks: \", len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a87ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Embeddings\n",
    "# from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "#vector = embeddings.embed_query(\"Hello World\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5605de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reteived_document length:  3\n"
     ]
    }
   ],
   "source": [
    "#VectorDB\n",
    "from langchain_chroma import Chroma\n",
    "vectoreStore = Chroma.from_documents(documents = docs, embedding= HuggingFaceEmbeddings())\n",
    "\n",
    "retreiver = vectoreStore.as_retriever(search_type=\"similarity\", search_kwargs = {\"k\":3})\n",
    "retreived_docs = retreiver.invoke(\"IDFC First Bank\")\n",
    "\n",
    "print(\"Reteived_document length: \", len(retreived_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Replace this with your actual Gemini API key\n",
    "api_key = \"AIzaSyBDVWe81KyuJAl8s5VzhYx64adg_sajLGY\"\n",
    "\n",
    "# Initialize Gemini 1.5 model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",   # or \"gemini-1.5-pro\"\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "#restaurant_name = 'Mexican'\n",
    "# Optional: use prompt template\n",
    "# prompt = PromptTemplate.from_template(\"Explain {topic} in simple terms.\")\n",
    "# parser = StrOutputParser()\n",
    "prompt_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest some fancy name for this\"\n",
    ")\n",
    "\n",
    "\n",
    "name_chain = prompt_name | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# Use LangChain chaining\n",
    "#chain = prompt | llm | parser\n",
    "\n",
    "\n",
    "# Run the chain\n",
    "# response = name_chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "# print(response)\n",
    "\n",
    "prompt_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}. Return it as comma seperated vallue\"\n",
    ")\n",
    "\n",
    "\n",
    "food_items_chain = prompt_items | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b256b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçΩÔ∏è Menu Items: Luna de Plata's Sunset Shrimp Scampi, Casa de Oro's  Chile-Rubbed Ribeye, Jard√≠n Secreto's  Mole Poblano with Quail, Agave & Ambrosia's  Cactus Pear & Goat Cheese Salad, Sol y Sombra's  Spicy Watermelon Gazpacho, Hacienda del Cielo's  Al Pastor-Spiced Lamb Chops, Fuego Sagrado's  Flamed-Grilled Octopus, Mezcal & Marigold's  Spicy Mango Margarita, Perla Negra's  Black Bean & Chorizo Empanadas, Cantina Celeste's  Star Anise-Infused  Carnitas, El Mole Perfecto, Cocina de las Especias's  Three-Chile-Pepper  Shrimp, Casa de los Chiles's  Chile Relleno Trio, Rancho de los Tacos's  Gourmet Taco Flight, The Avocado Blossom's  Creamy Avocado Soup,  [Neighborhood Name] Cantina's  Signature Margarita, [Landmark] Cocina's  Seafood Paella, [Street Name] Taqueria's  Street Corn Salad, Coraz√≥n de Fuego's  Spicy Chorizo & Potato Hash, Whispers of Oaxaca's  Oaxacan Black Mole Enchiladas, Aztec Bloom's  Cactus Flower Fritters, Maya's Moon's  Grilled Pineapple Salsa, Rio de Sabores's  River Trout with Chipotle-Lime Sauce\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "sequential_chain = (\n",
    "    name_chain\n",
    "    | RunnableLambda(lambda name: {\"restaurant_name\": name})\n",
    "    | food_items_chain\n",
    ")\n",
    "\n",
    "# ‚úÖ Run the full chain with a cuisine\n",
    "response = sequential_chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "print(\"üçΩÔ∏è Menu Items:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9accd2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "Answer the question based on your knowledge, Use the following contextto help:\n",
    "\n",
    "(context)\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "(question)\n",
    "</s>\n",
    "<|assistant|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variable = [\"context\", \"question\"],\n",
    "    template = prompt_template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c7e3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm Chain\n",
    "llm_chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01edd45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Please provide me with the context and the question. I need that information to be able to answer.\n"
     ]
    }
   ],
   "source": [
    "#Rag Chain\n",
    "\n",
    "\n",
    "# rag_chain = {\"context\": retreiver, \"question\": RunnablePassthrough()} | llm_chain\n",
    "\n",
    "# question = \"2025 Budget Highlights\"\n",
    "\n",
    "# response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "# response = response.replace(\"</s>\", \"\").strip()\n",
    "# print(\"Response\", response)\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "rag_chain = {\n",
    "    \"context\": retreiver,              # <- Your vector store retriever\n",
    "    \"question\": RunnablePassthrough()  # <- Directly forwards the question\n",
    "} | llm_chain\n",
    "\n",
    "# ‚úÖ 5. Invoke with a question\n",
    "question = \"IDFC First Bank Price\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "# ‚úÖ 6. Clean and print\n",
    "cleaned_response = response.replace(\"</s>\", \"\").strip()\n",
    "print(\"Response:\", cleaned_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30704fc6",
   "metadata": {},
   "source": [
    "#PROJECT1-- Scraping website and answer question based on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3458df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import streamlit as st\n",
    "import pickle\n",
    "import langchain\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab39f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.screener.in/company/IDFCFIRSTB/consolidated/',\n",
    "        'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/idfcfirstbank/IDF01',\n",
    "        'https://www.cnbctv18.com/market/stocks/idfc-first-bank-share-price/IDF01/']\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007b9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # seperator= [\"\\n\\n\",\"\\n\",\" \"],\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap =200\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16593e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0092750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"vector_index.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9bee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        vectorIndex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896363b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is the price of IDFC First Bank',\n",
       " 'answer': 'The provided text gives conflicting information about the price of IDFC First Bank.  One source states the current price is ‚Çπ68.4 (',\n",
       " 'sources': 'https://www.screener.in/company/IDFCFIRSTB/consolidated/), while another source gives a price of Rs. 68.30 on June 3, 2025 ('}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'what is the price of IDFC First Bank'\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever = vectorIndex.as_retriever())\n",
    "chain.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99644a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3018622388.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mMinu - Data Science\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Minu - Data Science\n",
    "Venu - MLops\n",
    "Sagar - fullStack\n",
    "Chandan- Database thing, Python Scripting\n",
    "Puru - Quality (J unit testing, pytest, langsmith)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d727e1",
   "metadata": {},
   "source": [
    "#PROJECT2 SQL Query Databse Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19858304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "\n",
    "db_user = \"root\"\n",
    "db_password = \"root\"\n",
    "db_host = \"localhost\"\n",
    "db_name = \"atliq_tshirts\"\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341faf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "qns1 = db_chain(\"How many t-Shirts do we have left for nike in extra small size and white color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shots = [\n",
    "    {'Question' : \"How many t-shirts do we have left for Nike in XS size and white color?\",\n",
    "     'SQLQuery' : \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Nike' AND color = 'White' AND size = 'XS'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : \"91\"},\n",
    "    {'Question': \"How much is the total price of the inventory for all S-size t-shirts?\",\n",
    "     'SQLQuery':\"SELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': \"22292\"},\n",
    "    {'Question': \"If we have to sell all the Levi‚Äôs T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\" ,\n",
    "     'SQLQuery' : \"\"\"SELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
    "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
    "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
    " \"\"\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': \"16725.4\"} ,\n",
    "     {'Question' : \"If we have to sell all the Levi‚Äôs T-shirts today. How much revenue our store will generate without discount?\" ,\n",
    "      'SQLQuery': \"SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\",\n",
    "      'SQLResult': \"Result of the SQL query\",\n",
    "      'Answer' : \"17462\"},\n",
    "    {'Question': \"How many white color Levi's shirt I have?\",\n",
    "     'SQLQuery' : \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : \"290\"\n",
    "     },\n",
    "    {'Question': \"how much sales amount will be generated if we sell all large size t shirts today in nike brand after discounts?\",\n",
    "     'SQLQuery' : \"\"\"SELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
    "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Nike' and size=\"L\"\n",
    "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_\n",
    "\n",
    "shirt_id\n",
    " \"\"\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : \"290\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain.chains.sql_database.prompt import PROMPT_SUFFIX, _mysql_prompt\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def get_few_shot_db_chain():\n",
    "    to_vectorize = [\" \".join(example.values()) for example in few_shots]\n",
    "    vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=few_shots)\n",
    "    example_selector = SemanticSimilarityExampleSelector(\n",
    "        vectorstore=vectorstore,\n",
    "        k=2,\n",
    "    )\n",
    "    mysql_prompt = \"\"\"You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "    Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
    "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "    Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
    "    \n",
    "    Use the following format:\n",
    "    \n",
    "    Question: Question here\n",
    "    SQLQuery: Query to run with no pre-amble\n",
    "    SQLResult: Result of the SQLQuery\n",
    "    Answer: Final answer here\n",
    "    \n",
    "    No pre-amble.\n",
    "    \"\"\"\n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"Question\", \"SQLQuery\", \"SQLResult\",\"Answer\",],\n",
    "        template=\"\\nQuestion: {Question}\\nSQLQuery: {SQLQuery}\\nSQLResult: {SQLResult}\\nAnswer: {Answer}\",\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        example_selector=example_selector,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=mysql_prompt,\n",
    "        suffix=PROMPT_SUFFIX,\n",
    "        input_variables=[\"input\", \"table_info\", \"top_k\"], #These variables are used in the prefix and suffix\n",
    "    )\n",
    "    chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, prompt=few_shot_prompt)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_few_shot_db_chain()\n",
    "chain.invoke(\"How much is the price for inventory for all small size t-shirts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54022ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"How many white color Levi's shirt I have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d52a4",
   "metadata": {},
   "source": [
    "#LANG GRAPH CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langgraph langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667815ab",
   "metadata": {},
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6960b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafcdd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entry Point\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f121a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e09cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2124284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
